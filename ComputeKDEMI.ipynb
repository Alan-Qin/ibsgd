{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import os, cPickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import kde\n",
    "import simplebinmi\n",
    "import keras.backend as K\n",
    "\n",
    "import utils\n",
    "trn, tst = utils.get_mnist()\n",
    "\n",
    "infoplane_measure = 'upper'\n",
    "infoplane_measure = 'bin'\n",
    "\n",
    "MAX_EPOCHS = 10000\n",
    "#MAX_EPOCHS = 10\n",
    "DO_SAVE=True\n",
    "ARCH = '1024-20-20-20'\n",
    "#ARCH = '20-20-20-20-20-20'\n",
    "#ARCH = '32-28-24-20-16-12'\n",
    "#ARCH = '32-28-24-20-16-12-8-8'\n",
    "BASE_DIRS = [ (act, 'rawdata/%s_%s/'%(act,ARCH)) for act in ['relu','tanh'] ]\n",
    "SKIP_RELU = False\n",
    "\n",
    "labelixs = [ tst.y == i for i in range(10) ]\n",
    "#BASE_DIRS = [ (act, 'rawdata/%s_128-64-32-16-16/'%act) for act in ['relu','tanh'] ]\n",
    "\n",
    "#BASE_DIRS = [ (act, 'rawdata/%s_20-20-20-20-20-20/'%act) for act in ['relu','tanh'] ]\n",
    "#BASE_DIRS = [ (act, 'rawdata/%s_50-20-20-20/'%act) for act in ['relu','tanh'] ]\n",
    "#BASE_DIRS = [ (act, 'rawdata/%s_20-20-20-20/'%act) for act in ['relu','tanh'] ]\n",
    "#BASE_DIRS = [ (act, 'rawdata/%s_100-50-20-20-20/'%act) for act in ['relu','tanh'] ]\n",
    "#BASE_DIRS = [ (act, 'rawdata/%s_20-20-20-20-20/'%act) for act in ['relu','tanh'] ]\n",
    "#BASE_DIRS = [ (act, 'rawdata/%s_100-50-20/'%act) for act in ['relu','tanh'] ]\n",
    "#variance = 0.25 # 1e-2 #  2e-1\n",
    "subsample = 1\n",
    "#variance = 0.25e-1 \n",
    "variance = 1e-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measures = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activityVariable = K.placeholder(ndim=2)\n",
    "entropy_func_upper = K.function([activityVariable,], [kde.entropy_estimator_kl(activityVariable, variance),])\n",
    "entropy_func_lower = K.function([activityVariable,], [kde.entropy_estimator_bd(activityVariable, variance),])\n",
    "\n",
    "from scipy.special import gammaln, psi\n",
    "\n",
    "#dist_func = K.function([activityVar,], [kde.Kget_dists(activityVar),])\n",
    "def Kentropy2(X, k=1):\n",
    "    if k != 1:\n",
    "        raise Exception('k must be 1')\n",
    "    dists = kde.Kget_dists(X)\n",
    "    \n",
    "    dims, N = kde.get_shape(X)\n",
    "    dists2 = dists + kde.tensor_eye(K.cast(N, 'int32')) * 10e20\n",
    "\n",
    "    nearest_neighbor = K.min(dists2, axis=1)\n",
    "    '''\n",
    "    F. Perez-Cruz, (2008). Estimation of Information Theoretic Measures\n",
    "    for Continuous Random Variables. Advances in Neural Information\n",
    "    Processing Systems 21 (NIPS). Vancouver (Canada), December.\n",
    " \n",
    "    return d*mean(log(r))+log(volume_unit_ball)+log(n-1)-log(k)\n",
    "    '''\n",
    "    return dims*K.mean(K.log(nearest_neighbor))#  + log_volume_unit_ball + psi(N) - psi(k)\n",
    "    #return d*np.mean(np.log(r))+log_volume_unit_ball+np.log(n-1)-np.log(k)\n",
    "\n",
    "entropy2_func = K.function([activityVariable,], [Kentropy2(activityVariable,),])\n",
    "def entropy2(X,k=1):\n",
    "    N, dims = X.shape\n",
    "    log_volume_unit_ball = 0.5*dims*np.log(np.pi) - gammaln(.5*dims + 1)\n",
    "    val = entropy2_func([X,])[0]\n",
    "    return val + log_volume_unit_ball + psi(N) - psi(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DO_PLOT_LAYERS = None\n",
    "DO_LOWER = False\n",
    "#del measures['tanh'][1800]\n",
    "#del measures['tanh'][1900]\n",
    "#del measures['tanh'][2000]\n",
    "#del measures['tanh'][20]\n",
    "\n",
    "\n",
    "for activation, BASE_DIR in BASE_DIRS:\n",
    "    if activation not in measures:\n",
    "        measures[activation] = {}\n",
    "    if SKIP_RELU and activation == 'relu':\n",
    "        continue\n",
    "    print('***************')\n",
    "    if not os.path.exists(BASE_DIR):\n",
    "        continue\n",
    "    for epochfile in sorted(os.listdir(BASE_DIR)):\n",
    "        if not epochfile.startswith('epoch'):\n",
    "            continue\n",
    "\n",
    "        epoch =  int(epochfile[len('epoch'):])\n",
    "        \n",
    "        if epoch in measures[activation]:\n",
    "            continue\n",
    "            \n",
    "        if epoch > MAX_EPOCHS:\n",
    "            continue\n",
    "\n",
    "        print(\"Doing %s%s\" %(BASE_DIR, epochfile))\n",
    "        \n",
    "        with open(BASE_DIR+ \"/\"+epochfile, 'rb') as f:\n",
    "            d = cPickle.load(f)\n",
    "\n",
    "        num_layers = len(d['data']['activity_tst'])\n",
    "\n",
    "        if DO_PLOT_LAYERS is None:\n",
    "            DO_PLOT_LAYERS = []\n",
    "            for lndx in range(num_layers):\n",
    "                #if d['data']['activity_tst'][lndx].shape[1] < 200 and lndx != num_layers - 1:\n",
    "                DO_PLOT_LAYERS.append(lndx)\n",
    "                \n",
    "        cepochdata = defaultdict(list)\n",
    "        for lndx in range(num_layers):\n",
    "            activity = d['data']['activity_tst'][lndx][::subsample]\n",
    "            if True: #  and lndx != num_layers - 1:\n",
    "                # Not the last layer\n",
    "                hM_given_X = kde.kde_condentropy(activity, variance)\n",
    "                h_upper = entropy_func_upper([activity,])[0]\n",
    "                if DO_LOWER:\n",
    "                    h_lower = entropy_func_lower([activity,])[0]\n",
    "\n",
    "                hM_given_Y_upper=0.\n",
    "                hM_given_Y_lower=0.\n",
    "                for i in range(10):\n",
    "                    ixs = tst.y[::subsample] == i\n",
    "                    hcond_upper = entropy_func_upper([activity[ixs,:],])[0]\n",
    "                    prob = np.mean(ixs)\n",
    "                    hM_given_Y_upper += prob * hcond_upper\n",
    "                    if DO_LOWER:\n",
    "                        hcond_lower = entropy_func_lower([activity[ixs,:],])[0]\n",
    "                        hM_given_Y_lower += prob * hcond_lower\n",
    "            else:\n",
    "                # The last layer. Treat probabilistically\n",
    "                ps = activity.mean(axis=0)\n",
    "                h_lower = h_upper = sum([-p*np.log(p) for p in ps if p != 0])\n",
    "\n",
    "                x = -activity * np.log(activity)\n",
    "                x[activity == 0] = 0.\n",
    "                hM_given_X = np.mean(x.sum(axis=1))\n",
    "\n",
    "                hM_given_Y=0.\n",
    "                for i in range(10):\n",
    "                    ixs = tst.y[::subsample] == i\n",
    "                    ps = activity[ixs,:].mean(axis=0)\n",
    "                    hcond = sum([-p*np.log(p) for p in ps if p != 0])\n",
    "                    prob = np.mean(ixs)\n",
    "                    hM_given_Y += prob * hcond\n",
    "                hM_given_Y_lower = hM_given_Y_upper = hM_given_Y\n",
    "                del hM_given_Y\n",
    "                \n",
    "            iLN2 = 1.0/np.log(2) # nats to bits\n",
    "        \n",
    "            cepochdata['MI_XM_upper'].append( iLN2*(h_upper-hM_given_X) )\n",
    "            cepochdata['MI_YM_upper'].append( iLN2*(h_upper-hM_given_Y_upper) )\n",
    "            cepochdata['H_M_upper'].append(iLN2*h_upper)\n",
    "\n",
    "            \n",
    "            if DO_LOWER:\n",
    "                cepochdata['MI_XM_lower'].append( iLN2*(h_lower-hM_given_X) )\n",
    "                cepochdata['MI_YM_lower'].append( iLN2*(h_lower-hM_given_Y_lower) )\n",
    "                cepochdata['H_M_lower'].append(iLN2*h_lower)\n",
    "\n",
    "            #measures[activation][epoch]['MI_XM_bin'].append(simplebinmi.bin_calc_information(tst.X, activity, 5)\n",
    "            binxm, binym = simplebinmi.bin_calc_information2(labelixs, activity, 0.5)\n",
    "            cepochdata['MI_XM_bin'].append(iLN2 * binxm)\n",
    "            cepochdata['MI_YM_bin'].append(iLN2 * binym)\n",
    "            \n",
    "            # h2 = entropy2(activity)\n",
    "            # #jointH = entropy2(np.hstack([tst.X, activity]), nnK)\n",
    "            # #mi2 = h2 + inputH - jointH\n",
    "            # cepochdata['H_M2'].append(iLN2*h2)\n",
    "            # #MI_XM2[epoch].append(mi2)\n",
    "\n",
    "            #print('- Layer %d: MI(X;M)=%0.3f, MI(Y;M)=%0.3f,  MI(X;M)bin=%0.3f'\n",
    "            #      %(lndx, lastd['MI_XM_upper'][-1], lastd['MI_YM_upper'][-1], lastd['MI_XM_bin'][-1]))\n",
    "            print('- Layer %d upper: MI(X;M)=%0.3f, MI(Y;M)=%0.3f / '\n",
    "                  %(lndx, cepochdata['MI_XM_upper'][-1], cepochdata['MI_YM_upper'][-1]),\n",
    "                 'bin: MI(X;M)=%0.3f, MI(Y;M)=%0.3f'\n",
    "                  %(cepochdata['MI_XM_bin'][-1], cepochdata['MI_YM_bin'][-1]))\n",
    "\n",
    "        measures[activation][epoch] = cepochdata\n",
    "        #print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#PLOT_LAYERS = [0,1,2,3,4] # [1,2,3]\n",
    "#PLOT_LAYERS = [0,1,2,3]\n",
    "#PLOT_LAYERS = [0,1,2,3]\n",
    "plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(4,2)\n",
    "for actndx, (activation, _) in enumerate(BASE_DIRS):\n",
    "    if activation not in measures:\n",
    "        print(\"Skipping\", activation)\n",
    "        continue\n",
    "    epochs = sorted(measures[activation].keys())\n",
    "    plt.subplot(gs[0,actndx])\n",
    "    for lndx, layerid in enumerate(DO_PLOT_LAYERS):\n",
    "        #for epoch in epochs:\n",
    "        #    print('her',epoch, measures[activation][epoch]['MI_XM_upper'])\n",
    "        xmvalsU = np.array([measures[activation][epoch]['H_M_upper'][layerid] for epoch in epochs])\n",
    "        if DO_LOWER:\n",
    "            xmvalsL = np.array([measures[activation][epoch]['H_M_lower'][layerid] for epoch in epochs])\n",
    "        plt.plot(epochs, xmvalsU, label='Layer %d'%layerid)\n",
    "        #plt.errorbar(epochs, (xmvalsL + xmvalsU)/2,xmvalsU - xmvalsL, label='Layer %d'%layerid)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.title(activation)\n",
    "    plt.ylabel('H(M)')\n",
    "    \n",
    "    plt.subplot(gs[1,actndx])\n",
    "    for lndx, layerid in enumerate(DO_PLOT_LAYERS):\n",
    "        #for epoch in epochs:\n",
    "        #    print('her',epoch, measures[activation][epoch]['MI_XM_upper'])\n",
    "        xmvalsU = np.array([measures[activation][epoch]['MI_XM_upper'][layerid] for epoch in epochs])\n",
    "        if DO_LOWER:\n",
    "            xmvalsL = np.array([measures[activation][epoch]['MI_XM_lower'][layerid] for epoch in epochs])\n",
    "        plt.plot(epochs, xmvalsU, label='Layer %d'%layerid)\n",
    "        #plt.errorbar(epochs, (xmvalsL + xmvalsU)/2,xmvalsU - xmvalsL, label='Layer %d'%layerid)\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel('I(X;M)')\n",
    "\n",
    "\n",
    "    plt.subplot(gs[2,actndx])\n",
    "    for lndx, layerid in enumerate(DO_PLOT_LAYERS):\n",
    "        ymvalsU = np.array([measures[activation][epoch]['MI_YM_upper'][layerid] for epoch in epochs])\n",
    "        if DO_LOWER:\n",
    "            ymvalsL = np.array([measures[activation][epoch]['MI_YM_lower'][layerid] for epoch in epochs])\n",
    "        plt.plot(epochs, ymvalsU, label='Layer %d'%layerid)\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel('MI(Y;M)')\n",
    "\n",
    "    plt.subplot(gs[3,actndx])\n",
    "    for lndx, layerid in enumerate(DO_PLOT_LAYERS):\n",
    "        #h2vals = np.array([measures[activation][epoch]['H_M2'][layerid] for epoch in epochs])\n",
    "        h2vals = np.array([measures[activation][epoch]['MI_XM_bin'][layerid] for epoch in epochs])\n",
    "        plt.semilogx(epochs, h2vals, label='Layer %d'%layerid)\n",
    "    plt.xlabel('Epoch')\n",
    "    #plt.ylabel(\"H'(M)\")\n",
    "    plt.ylabel(\"I(X;M)bin\")\n",
    "    #plt.yscale('log')\n",
    "    \n",
    "    if actndx == 0:\n",
    "        plt.legend(loc='lower right')\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#PLOT_LAYERS = [1,2,3]\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "max_epoch = max( (max(measures[activation].keys()) if len(measures[activation]) else 0) for activation, _ in BASE_DIRS)\n",
    "sm = plt.cm.ScalarMappable(cmap='gnuplot', norm=plt.Normalize(vmin=0, vmax=max_epoch))\n",
    "sm._A = []\n",
    "\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "for actndx, (activation, _) in enumerate(BASE_DIRS):\n",
    "    epochs = sorted(measures[activation].keys())\n",
    "    plt.subplot(1,2,actndx+1)    \n",
    "    #     if actndx == 0:\n",
    "    #         ax1 = plt.subplot(1,2,actndx+1)\n",
    "    #     else:\n",
    "    #         plt.subplot(1,2,actndx+1, sharey=ax1)\n",
    "    for epoch in epochs:\n",
    "        c = sm.to_rgba(epoch)\n",
    "        xmvals = np.array(measures[activation][epoch]['MI_XM_'+infoplane_measure])[DO_PLOT_LAYERS]\n",
    "        ymvals = np.array(measures[activation][epoch]['MI_YM_'+infoplane_measure])[DO_PLOT_LAYERS]\n",
    "\n",
    "        plt.plot(xmvals, ymvals, c=c, alpha=0.1, zorder=1)\n",
    "        plt.scatter(xmvals, ymvals, s=20, facecolors=[c for _ in DO_PLOT_LAYERS], edgecolor='none', zorder=2)\n",
    "    \n",
    "    plt.ylim([0, 3.5])\n",
    "    plt.xlim([0, 14])\n",
    "    plt.xlabel('I(X;M)')\n",
    "    plt.ylabel('I(Y;M)')\n",
    "    plt.title(activation)\n",
    "    \n",
    "cbaxes = fig.add_axes([1.0, 0.125, 0.03, 0.8]) \n",
    "plt.colorbar(sm, label='Epoch', cax=cbaxes)\n",
    "plt.tight_layout()\n",
    "\n",
    "if DO_SAVE:\n",
    "    plt.savefig('infoplane-%s-%s.pdf'%(ARCH,infoplane_measure),bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adsfsdfasdf\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "gs = gridspec.GridSpec(len(BASE_DIRS), len(PLOT_LAYERS))\n",
    "for actndx, (activation, BASE_DIR) in enumerate(BASE_DIRS):\n",
    "    epochs = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    wnorms = []\n",
    "    if not os.path.exists(BASE_DIR):\n",
    "        continue\n",
    "    for epochfile in sorted(os.listdir(BASE_DIR)):\n",
    "        if not epochfile.startswith('epoch'):\n",
    "            continue\n",
    "\n",
    "        epoch =  int(epochfile[len('epoch'):])\n",
    "        if epoch > MAX_EPOCHS:\n",
    "            continue\n",
    "\n",
    "        with open(BASE_DIR+ \"/\"+epochfile, 'rb') as f:\n",
    "            d = cPickle.load(f)\n",
    "            \n",
    "        epochs.append(epoch)\n",
    "        wnorms.append(d['data']['weights_norm'])\n",
    "        means.append(d['data']['gradmean'])\n",
    "        stds.append(d['data']['gradstd'])\n",
    "\n",
    "    wnorms, means, stds = map(np.array, [wnorms, means, stds])\n",
    "    for lndx,layerid in enumerate(PLOT_LAYERS):\n",
    "        plt.subplot(gs[actndx, lndx])\n",
    "        plt.plot(epochs, means[:,layerid], 'b', label=\"Mean\")\n",
    "        plt.plot(epochs, stds[:,layerid], 'orange', label=\"Std\")\n",
    "        plt.plot(epochs, means[:,layerid]/stds[:,layerid], 'red', label=\"SNR\")\n",
    "        plt.plot(epochs, wnorms[:,layerid], 'g', label=\"||W||\")\n",
    "\n",
    "        #plt.ylabel('Layer %d - SNR'%rowndx)\n",
    "        #plt.subplot(gs[rowndx*2+1,colndx])\n",
    "        #plt.plot(epochs, [saved_logs[epoch][t+'_layer_%d_weightsnorm' % rowndx] for epoch in epochs], 'b', label=\"Weight norm\")\n",
    "        #plt.ylabel('Layer %d - ||Weights||'%rowndx)\n",
    "        #plt.xlabel('Epochs')\n",
    "        plt.title('Layer %d'%layerid)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.gca().set_xscale(\"log\", nonposx='clip')\n",
    "        plt.gca().set_yscale(\"log\", nonposy='clip')\n",
    "    \n",
    "\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropy_func_upper = K.function([activityVar,], [kde.entropy_estimator_kl(activityVar, variance),])\n",
    "\n",
    "plt.figure()\n",
    "for epoch in (100, 2000):\n",
    "    with open(\"rawdata/tanh_20-20-20-20/epoch%08d\"%epoch, 'rb') as f:\n",
    "        d = cPickle.load(f)\n",
    "        activity = d['data']['activity_tst'][3]\n",
    "        plt.figure()\n",
    "        plt.hist(activity.flatten())\n",
    "        print(epoch, entropy_func_upper([activity,])[0])\n",
    "\n",
    "# plt.figure()\n",
    "# with open(\"rawdata/tanh_1024-20-20-20/epoch%08d\"%100, 'rb') as f:\n",
    "#     d = cPickle.load(f)\n",
    "#     activity = d['data']['activity_tst'][3]\n",
    "#     plt.hist(activity.flatten())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmvalsU = np.array([measures['tanh'][epoch]['MI_XM_upper'][layerid] for epoch in epochs])\n",
    "print(xmvalsU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import kde\n",
    "X = np.random.random((10000,100))*10\n",
    "print(np.log(10000))\n",
    "print(entropy_func_upper([X,]) - kde.kde_condentropy(X, variance))\n",
    "print(entropy_func_upper([X,]))\n",
    "d2 = K.function([activityVar,], [kde.Kget_dists(activityVar),])\n",
    "dists = d2([X,])[0]\n",
    "\n",
    "from scipy.misc import logsumexp\n",
    "N, dims = X.shape\n",
    "#dims, N = get_shape(x)\n",
    "# dists = Kget_dists(x)\n",
    "dists2 = dists / (2*variance)\n",
    "normconst = (dims/2.0)*np.log(2*np.pi*variance)\n",
    "lprobs = logsumexp(-dists2, axis=1) - np.log(N) - normconst\n",
    "print(lprobs)\n",
    "h = -np.mean(lprobs)\n",
    "v= dims/2 + h\n",
    "print(v)\n",
    "print(normconst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dims, N = get_shape(x)\n",
    "val = entropy_estimator_kl(x,4*var)\n",
    "return val + np.log(0.25)*dims/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
